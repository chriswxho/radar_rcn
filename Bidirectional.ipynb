{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a161a5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f307dd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0451637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " '.fseventsd',\n",
       " '.Spotlight-V100',\n",
       " '.TemporaryItems',\n",
       " '.Trashes',\n",
       " 'IDRad',\n",
       " 'Install Western Digital Software for Mac.dmg',\n",
       " 'Install Western Digital Software for Windows.exe',\n",
       " 'Vimeo']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/Volumes/PassportDrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb00dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR = '/Volumes/Untitled/IDRad/idrad'\n",
    "DATA_DIR = '/Users/davidzhu/Desktop/IDRad/idrad'\n",
    "DEFAULT_FILE = 'train/target5_001.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e011a7c0",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a496999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aefcc3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_doppler(data, chirps=256,\n",
    "                  samples=256,\n",
    "                  fft_rangesamples=2 ** 10,\n",
    "                  fft_dopplersamples=2 ** 8,\n",
    "                  fs=2.0e6,\n",
    "                  kf=1171875.0e7,\n",
    "                  min_range=0.5,\n",
    "                  max_range=10):\n",
    "    \"\"\"\n",
    "    Computes a range-doppler map for a given number of chirps and samples per chirp.\n",
    "    :param data: FMCW radar data frame consisting of <chirps>x<samples>\n",
    "    :param chirps: Number of chirps (Np)\n",
    "    :param samples: Number of samples (N)\n",
    "    :param fft_rangesamples: Number of samples for the range fft.\n",
    "    :param fft_dopplersamples: Number of samples for the doppler fft.\n",
    "    :param fs: Constant depending on the radar recording parameters.\n",
    "    :param kf: Constant depending on the radar recording parameters.\n",
    "    :param min_range: Minimum value to take into account for the range axis in the range-doppler map.\n",
    "    :param max_range: Maximum value to take into account for the range axis in the range-doppler map.\n",
    "    :return: Returns a 2D dimensional range-doppler map representing the reflected power over all range-doppler bins.\n",
    "    \"\"\"\n",
    "\n",
    "    data = data.reshape(chirps, samples).T\n",
    "    # Ignore chirp sequence number\n",
    "    data = data[1:]\n",
    "    Ny, Nx = data.shape  # rows (N), columns (Np)\n",
    "\n",
    "    window = np.hanning(Ny)\n",
    "    scaled = np.sum(window)\n",
    "    window2d = np.tile(window, (Nx, 1)).T\n",
    "    data = data * window2d\n",
    "\n",
    "    # Calculate Range FFT\n",
    "    x = np.zeros((fft_rangesamples, Nx))\n",
    "    start_index = int((fft_rangesamples - Ny) / 2)\n",
    "    x[start_index:start_index + Ny, :] = data\n",
    "    X = np.fft.fft(x, fft_rangesamples, 0) / scaled * (2.0 / 2048)\n",
    "    # Extract positive range bins\n",
    "    X = X[0:fft_rangesamples // 2, :]\n",
    "    # Extract range\n",
    "    _freq = np.arange(fft_rangesamples // 2) / float(fft_rangesamples) * fs\n",
    "    _range = _freq * 3e8 / (2 * kf)\n",
    "    min_index = np.argmin(np.abs(_range - min_range))\n",
    "    max_index = np.argmin(np.abs(_range - max_range))\n",
    "\n",
    "    X = X[min_index: max_index, :]\n",
    "\n",
    "    # Calculate Doppler FFT\n",
    "    Ny, Nx = X.shape\n",
    "    window = np.hanning(Nx)\n",
    "    scaled = np.sum(window)\n",
    "    window2d = np.tile(window, (Ny, 1))\n",
    "    X = X * window2d\n",
    "\n",
    "    rd = np.zeros((Ny, fft_dopplersamples), dtype='complex_')\n",
    "    start_index = int((fft_dopplersamples - Nx) / 2)\n",
    "    rd[:, start_index:start_index + Nx] = X\n",
    "\n",
    "    range_doppler = np.fft.fft(rd, fft_dopplersamples, 1) / scaled\n",
    "    range_doppler = np.fft.fftshift(range_doppler, axes=1)\n",
    "\n",
    "    return np.abs(range_doppler)\n",
    "\n",
    "def preprocess_file(fname): \n",
    "    with h5py.File(f'{DATA_DIR}/{fname}', 'r+') as file:\n",
    "        nframes = file['radar'].shape[0]\n",
    "\n",
    "        # Create datasets\n",
    "        if not 'microdoppler' in file:\n",
    "            file.create_dataset(\"microdoppler\", (nframes, 256), dtype='float32', chunks=(1, 256))\n",
    "        if not 'microdoppler_thresholded' in file:\n",
    "            file.create_dataset(\"microdoppler_thresholded\", (nframes, 256), dtype='float32', chunks=(1, 256))\n",
    "        if not 'range_doppler' in file:\n",
    "            file.create_dataset(\"range_doppler\", (nframes, 380, 256), dtype='float32', chunks=True)\n",
    "\n",
    "        \n",
    "        x = file['range_doppler'][:10,:,:]\n",
    "        \n",
    "        #has not been preprocessed\n",
    "        if np.all(x==0): \n",
    "            print('preprocessing')\n",
    "        \n",
    "            # Run over each radar frame\n",
    "            for i in range(nframes): # only take first 1000 \n",
    "                rd = range_doppler(file['radar'][i]) \n",
    "                rd = 20 * np.log10(rd)\n",
    "\n",
    "                file['range_doppler'][i] = rd\n",
    "                file['microdoppler'][i] = rd.sum(axis=0)\n",
    "\n",
    "                rd -= np.amax(rd)\n",
    "                rd[rd < -45] = -45\n",
    "                file['microdoppler_thresholded'][i] = rd.sum(axis=0)\n",
    "\n",
    "                if not i%100: \n",
    "                    print(\"Finished frame %d of %d.\" % (i + 1, nframes))\n",
    "                    \n",
    "def get_range_doppler(fname): \n",
    "    '''returns the range doppler'''\n",
    "    preprocess_file(fname) \n",
    "    range_doppler = 0 \n",
    "    \n",
    "    with h5py.File(f'{DATA_DIR}/{fname}', 'r+') as file:\n",
    "        # d['microdoppler'] = file['microdoppler'][:,:]\n",
    "        # d['microdoppler_thresholded'] = file['microdoppler_thresholded'][:,:]\n",
    "        range_doppler = file['range_doppler'][:,:,:].sum(axis=1)\n",
    "    \n",
    "    return range_doppler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ef8c7fc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_files = os.listdir(f'{DATA_DIR}/train')\n",
    "dataset = [] \n",
    "labels = []\n",
    "labels_repeat = [] \n",
    "\n",
    "for fname in dataset_files: \n",
    "    if fname[:2] == '._':\n",
    "        print(fname)\n",
    "        continue \n",
    "    labels.append(int(fname[6]))\n",
    "    dataset.append(get_range_doppler(f'train/{fname}'))\n",
    "    labels_repeat.append(np.repeat(int(fname[6]), dataset[-1].shape[0] ))\n",
    "\n",
    "# dataset = np.array(dataset) \n",
    "labels = np.array(labels)\n",
    "labels_repeat = np.array(labels_repeat, dtype = object)\n",
    "dataset = np.array(dataset, dtype = object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b44ee442",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = np.array(dataset, dtype = object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd801ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f9df5ac2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130,)\n",
      "(130,)\n",
      "(130,)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "print(labels.shape)\n",
    "print(labels_repeat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cdd9caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_hot = np.zeros((labels.size, dataset.shape[1], labels.max()))\n",
    "labels_hot[np.arange(labels.size),:,labels-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "504f2feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import isfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10af508",
   "metadata": {},
   "source": [
    "# Layer Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10043488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrcn.base.blocks import InputToNode, BatchIntrinsicPlasticity, NodeToNode, HebbianNodeToNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9a79e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrcn.echo_state_network import ESNRegressor, ESNClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bf4d10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrcn.base.blocks import InputToNode, PredefinedWeightsInputToNode, NodeToNode\n",
    "from pyrcn.metrics import accuracy_score, classification_report, confusion_matrix, mean_squared_error\n",
    "from pyrcn.model_selection import SequentialSearchCV\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import make_scorer, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, ParameterGrid\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.utils.fixes import loguniform\n",
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7258097",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_rd = get_range_doppler(DEFAULT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65e6c459",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1_size = 125\n",
    "layer2_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "67c80351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bilayered; i2n -> n2o, second layer has fewer (125) nodes\n",
    "\n",
    "i2n = InputToNode(hidden_layer_size=layer1_size, input_activation=\"tanh\", input_scaling=1.0, bias_scaling=0.1)\n",
    "\n",
    "# layer1 = i2n.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b9ddc075",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layer1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [60]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlayer1\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'layer1' is not defined"
     ]
    }
   ],
   "source": [
    "layer1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a6171882",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_params = {'hidden_layer_size': layer2_size, #1000 in 5C\n",
    "                  'input_activation': 'identity', #\n",
    "                  # 'k_in': layer1_size, # number of inputs \n",
    "                  'bias_scaling': 0.0, # usually 0 \n",
    "                  'spectral_radius' : 0.0, \n",
    "                  'reservoir_activation': 'tanh', # 2\n",
    "                  'leakage': 0.05, #equation 6, 17 frames should be 1 step \n",
    "                  'bidirectional': True, #bidirectional \n",
    "                  'k_rec': 10,\n",
    "                  'alpha': 1e-5,\n",
    "                  'random_state': 1,\n",
    "                  'requires_sequence': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "60a03477",
   "metadata": {},
   "outputs": [],
   "source": [
    "n2o = ESNClassifier(**initial_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "69d1ed70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ESNClassifier(input_to_node=InputToNode(bias_scaling=0.0,\n",
       "                                        input_activation='identity',\n",
       "                                        random_state=1),\n",
       "              node_to_node=NodeToNode(bidirectional=True, k_rec=10,\n",
       "                                      leakage=0.05, random_state=1,\n",
       "                                      sparsity=0.02, spectral_radius=0.0),\n",
       "              regressor=IncrementalRegression(), requires_sequence=True)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n2o.fit(dataset, labels_repeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5996138a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = n2o.predict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5ebb127e",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = []\n",
    "for i, prediction in enumerate(predictions):  \n",
    "    \n",
    "    correct.append((prediction == labels[i]).mean())\n",
    "\n",
    "correct = np.array(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0beffe73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32139989854259865"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71499220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df71c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ec409d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec344475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1622aef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "469a4b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model from multipitch tracking examples \n",
    "\n",
    "initially_fixed_params = {'hidden_layer_size': 500,\n",
    "                          'input_activation': 'identity',\n",
    "                          'k_in': 10,\n",
    "                          'bias_scaling': 0.0,\n",
    "                          'reservoir_activation': 'tanh',\n",
    "                          'leakage': 1.0,\n",
    "                          'bidirectional': False,\n",
    "                          'k_rec': 10,\n",
    "                          'alpha': 1e-5,\n",
    "                          'random_state': 42,\n",
    "                          'requires_sequence': True}\n",
    "\n",
    "step1_esn_params = {'leakage': np.linspace(0.1, 1.0, 10)}\n",
    "kwargs_1 = {'random_state': 42, 'verbose': 2, 'n_jobs': 70, 'pre_dispatch': 70, 'n_iter': 14,\n",
    "           'scoring': make_scorer(accuracy_score)}\n",
    "step2_esn_params = {'input_scaling': np.linspace(0.1, 1.0, 10),\n",
    "                    'spectral_radius': np.linspace(0.0, 1.5, 16)}\n",
    "\n",
    "step3_esn_params = {'bias_scaling': np.linspace(0.0, 2.0, 21)}\n",
    "\n",
    "kwargs_2_3 = {'verbose': 2, 'pre_dispatch': 70, 'n_jobs': 70, \n",
    "              'scoring': make_scorer(accuracy_score)}\n",
    "\n",
    "# The searches are defined similarly to the steps of a sklearn.pipeline.Pipeline:\n",
    "searches = [('step1', GridSearchCV, step1_esn_params, kwargs_1),\n",
    "            ('step2', GridSearchCV, step2_esn_params, kwargs_2_3),\n",
    "            ('step3', GridSearchCV, step3_esn_params, kwargs_2_3)]\n",
    "\n",
    "base_esn = ESNClassifier(**initially_fixed_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d093aa97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ESNClassifier(input_to_node=InputToNode(bias_scaling=0.0,\n",
       "                                        input_activation='identity', k_in=10,\n",
       "                                        sparsity=0.0390625),\n",
       "              node_to_node=NodeToNode(k_rec=10, sparsity=0.02),\n",
       "              regressor=IncrementalRegression(), requires_sequence=True)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_esn.fit(dataset, labels_repeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "912dd2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = base_esn.predict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "43309084",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = []\n",
    "for i, prediction in enumerate(predictions):  \n",
    "    \n",
    "    correct.append((prediction == labels[i]).mean())\n",
    "\n",
    "correct = np.array(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f88189e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.295484848134971"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f10e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "echo-venv",
   "language": "python",
   "name": "echo-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
