{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a161a5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f307dd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0451637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['System Volume Information',\n",
       " '$RECYCLE.BIN',\n",
       " '.Spotlight-V100',\n",
       " 'Xilinx',\n",
       " '.fseventsd',\n",
       " 'ECG_data',\n",
       " 'Research Code',\n",
       " 'IDRad',\n",
       " 'REDS',\n",
       " 'Vimeo']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.listdir('/Volumes/Untitled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fb00dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR = '/Volumes/Untitled/IDRad/idrad'\n",
    "DATA_DIR = 'idrad'\n",
    "DATA_DIR = '/Users/davidzhu/Desktop/IDRad/idrad'\n",
    "DEFAULT_FILE = 'train/target5_001.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e011a7c0",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aefcc3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_doppler(data, chirps=256,\n",
    "                  samples=256,\n",
    "                  fft_rangesamples=2 ** 10,\n",
    "                  fft_dopplersamples=2 ** 8,\n",
    "                  fs=2.0e6,\n",
    "                  kf=1171875.0e7,\n",
    "                  min_range=0.5,\n",
    "                  max_range=10):\n",
    "    \"\"\"\n",
    "    Computes a range-doppler map for a given number of chirps and samples per chirp.\n",
    "    :param data: FMCW radar data frame consisting of <chirps>x<samples>\n",
    "    :param chirps: Number of chirps (Np)\n",
    "    :param samples: Number of samples (N)\n",
    "    :param fft_rangesamples: Number of samples for the range fft.\n",
    "    :param fft_dopplersamples: Number of samples for the doppler fft.\n",
    "    :param fs: Constant depending on the radar recording parameters.\n",
    "    :param kf: Constant depending on the radar recording parameters.\n",
    "    :param min_range: Minimum value to take into account for the range axis in the range-doppler map.\n",
    "    :param max_range: Maximum value to take into account for the range axis in the range-doppler map.\n",
    "    :return: Returns a 2D dimensional range-doppler map representing the reflected power over all range-doppler bins.\n",
    "    \"\"\"\n",
    "\n",
    "    data = data.reshape(chirps, samples).T\n",
    "    # Ignore chirp sequence number\n",
    "    data = data[1:]\n",
    "    Ny, Nx = data.shape  # rows (N), columns (Np)\n",
    "\n",
    "    window = np.hanning(Ny)\n",
    "    scaled = np.sum(window)\n",
    "    window2d = np.tile(window, (Nx, 1)).T\n",
    "    data = data * window2d\n",
    "\n",
    "    # Calculate Range FFT\n",
    "    x = np.zeros((fft_rangesamples, Nx))\n",
    "    start_index = int((fft_rangesamples - Ny) / 2)\n",
    "    x[start_index:start_index + Ny, :] = data\n",
    "    X = np.fft.fft(x, fft_rangesamples, 0) / scaled * (2.0 / 2048)\n",
    "    # Extract positive range bins\n",
    "    X = X[0:fft_rangesamples // 2, :]\n",
    "    # Extract range\n",
    "    _freq = np.arange(fft_rangesamples // 2) / float(fft_rangesamples) * fs\n",
    "    _range = _freq * 3e8 / (2 * kf)\n",
    "    min_index = np.argmin(np.abs(_range - min_range))\n",
    "    max_index = np.argmin(np.abs(_range - max_range))\n",
    "\n",
    "    X = X[min_index: max_index, :]\n",
    "\n",
    "    # Calculate Doppler FFT\n",
    "    Ny, Nx = X.shape\n",
    "    window = np.hanning(Nx)\n",
    "    scaled = np.sum(window)\n",
    "    window2d = np.tile(window, (Ny, 1))\n",
    "    X = X * window2d\n",
    "\n",
    "    rd = np.zeros((Ny, fft_dopplersamples), dtype='complex_')\n",
    "    start_index = int((fft_dopplersamples - Nx) / 2)\n",
    "    rd[:, start_index:start_index + Nx] = X\n",
    "\n",
    "    range_doppler = np.fft.fft(rd, fft_dopplersamples, 1) / scaled\n",
    "    range_doppler = np.fft.fftshift(range_doppler, axes=1)\n",
    "\n",
    "    return np.abs(range_doppler)\n",
    "\n",
    "def preprocess_file(fname): \n",
    "    with h5py.File(f'{DATA_DIR}/{fname}', 'r+') as file:\n",
    "        nframes = file['radar'].shape[0]\n",
    "\n",
    "        # Create datasets\n",
    "        if not 'microdoppler' in file:\n",
    "            file.create_dataset(\"microdoppler\", (nframes, 256), dtype='float32', chunks=(1, 256))\n",
    "        if not 'microdoppler_thresholded' in file:\n",
    "            file.create_dataset(\"microdoppler_thresholded\", (nframes, 256), dtype='float32', chunks=(1, 256))\n",
    "        if not 'range_doppler' in file:\n",
    "            file.create_dataset(\"range_doppler\", (nframes, 380, 256), dtype='float32', chunks=True)\n",
    "\n",
    "        \n",
    "        x = file['range_doppler'][:10,:,:]\n",
    "        \n",
    "        #has not been preprocessed\n",
    "        if np.all(x==0): \n",
    "            print('preprocessing')\n",
    "        \n",
    "            # Run over each radar frame\n",
    "            for i in range(nframes): # only take first 1000 \n",
    "                rd = range_doppler(file['radar'][i]) \n",
    "                rd = 20 * np.log10(rd)\n",
    "\n",
    "                file['range_doppler'][i] = rd\n",
    "                file['microdoppler'][i] = rd.sum(axis=0)\n",
    "\n",
    "                rd -= np.amax(rd)\n",
    "                rd[rd < -45] = -45\n",
    "                file['microdoppler_thresholded'][i] = rd.sum(axis=0)\n",
    "\n",
    "                if not i%100: \n",
    "                    print(\"Finished frame %d of %d.\" % (i + 1, nframes))\n",
    "                    \n",
    "def get_range_doppler(fname): \n",
    "    '''returns the range doppler'''\n",
    "    preprocess_file(fname) \n",
    "    range_doppler = 0 \n",
    "    \n",
    "    with h5py.File(f'{DATA_DIR}/{fname}', 'r+') as file:\n",
    "        # d['microdoppler'] = file['microdoppler'][:,:]\n",
    "        # d['microdoppler_thresholded'] = file['microdoppler_thresholded'][:,:]\n",
    "        range_doppler = file['range_doppler'][:,:,:].sum(axis=1)\n",
    "    \n",
    "    return range_doppler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ef8c7fc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "._target2_017.hdf5\n",
      "._target3_105.hdf5\n",
      "._target3_113.hdf5\n",
      "._target1_073.hdf5\n",
      "._target4_051.hdf5\n",
      "._target3_129.hdf5\n",
      "._target4_047.hdf5\n",
      "._target4_067.hdf5\n",
      "._target3_109.hdf5\n",
      "._target1_090.hdf5\n",
      "._target2_021.hdf5\n",
      "._target1_086.hdf5\n",
      "._target3_125.hdf5\n",
      "._target1_069.hdf5\n",
      "._target1_087.hdf5\n",
      "._target3_124.hdf5\n",
      "._target1_068.hdf5\n",
      "._target2_020.hdf5\n",
      "._target1_091.hdf5\n",
      "._target3_108.hdf5\n",
      "._target4_066.hdf5\n",
      "._target4_046.hdf5\n",
      "._target3_128.hdf5\n",
      "._target4_050.hdf5\n",
      "._target1_072.hdf5\n",
      "._target3_112.hdf5\n",
      "._target3_104.hdf5\n",
      "._target2_016.hdf5\n",
      "._target4_036.hdf5\n",
      "._target4_061.hdf5\n",
      "._target3_119.hdf5\n",
      "._target1_096.hdf5\n",
      "._target1_079.hdf5\n",
      "._target2_027.hdf5\n",
      "._target2_031.hdf5\n",
      "._target1_080.hdf5\n",
      "._target3_123.hdf5\n",
      "._target2_011.hdf5\n",
      "._target3_103.hdf5\n",
      "._target3_115.hdf5\n",
      "._target2_007.hdf5\n",
      "._target1_075.hdf5\n",
      "._target4_057.hdf5\n",
      "._target4_041.hdf5\n",
      "._target4_040.hdf5\n",
      "._target5_001.hdf5\n",
      "._target4_056.hdf5\n",
      "._target1_074.hdf5\n",
      "._target2_006.hdf5\n",
      "._target3_114.hdf5\n",
      "._target3_102.hdf5\n",
      "._target2_010.hdf5\n",
      "._target1_081.hdf5\n",
      "._target3_122.hdf5\n",
      "._target2_030.hdf5\n",
      "._target2_026.hdf5\n",
      "._target1_097.hdf5\n",
      "._target1_078.hdf5\n",
      "._target3_118.hdf5\n",
      "._target4_060.hdf5\n",
      "._target4_037.hdf5\n",
      "._target3_121.hdf5\n",
      "._target1_082.hdf5\n",
      "._target2_033.hdf5\n",
      "._target2_025.hdf5\n",
      "._target1_094.hdf5\n",
      "._target4_059.hdf5\n",
      "._target2_009.hdf5\n",
      "._target4_063.hdf5\n",
      "._target4_043.hdf5\n",
      "._target5_002.hdf5\n",
      "._target2_029.hdf5\n",
      "._target4_055.hdf5\n",
      "._target1_077.hdf5\n",
      "._target1_098.hdf5\n",
      "._target2_005.hdf5\n",
      "._target3_117.hdf5\n",
      "._target3_101.hdf5\n",
      "._target4_038.hdf5\n",
      "._target2_013.hdf5\n",
      "._target2_012.hdf5\n",
      "._target4_039.hdf5\n",
      "._target3_100.hdf5\n",
      "._target3_116.hdf5\n",
      "._target2_004.hdf5\n",
      "._target1_076.hdf5\n",
      "._target1_099.hdf5\n",
      "._target4_054.hdf5\n",
      "._target2_028.hdf5\n",
      "._target5_003.hdf5\n",
      "._target4_042.hdf5\n",
      "._target4_062.hdf5\n",
      "._target2_008.hdf5\n",
      "._target4_058.hdf5\n",
      "._target1_095.hdf5\n",
      "._target2_024.hdf5\n",
      "._target2_032.hdf5\n",
      "._target3_120.hdf5\n",
      "._target1_083.hdf5\n",
      "._target4_045.hdf5\n",
      "._target1_088.hdf5\n",
      "._target4_053.hdf5\n",
      "._target1_071.hdf5\n",
      "._target3_111.hdf5\n",
      "._target3_107.hdf5\n",
      "._target2_015.hdf5\n",
      "._target3_127.hdf5\n",
      "._target1_084.hdf5\n",
      "._target4_049.hdf5\n",
      "._target2_035.hdf5\n",
      "._target2_023.hdf5\n",
      "._target1_092.hdf5\n",
      "._target4_065.hdf5\n",
      "._target2_019.hdf5\n",
      "._target2_018.hdf5\n",
      "._target4_064.hdf5\n",
      "._target3_130.hdf5\n",
      "._target1_093.hdf5\n",
      "._target2_022.hdf5\n",
      "._target2_034.hdf5\n",
      "._target4_048.hdf5\n",
      "._target3_126.hdf5\n",
      "._target1_085.hdf5\n",
      "._target2_014.hdf5\n",
      "._target3_106.hdf5\n",
      "._target3_110.hdf5\n",
      "._target1_070.hdf5\n",
      "._target4_052.hdf5\n",
      "._target1_089.hdf5\n",
      "._target4_044.hdf5\n"
     ]
    }
   ],
   "source": [
    "dataset_files = os.listdir(f'{DATA_DIR}/train')\n",
    "dataset = [] \n",
    "labels = []\n",
    "\n",
    "for fname in dataset_files: \n",
    "    if fname[:2] == '._':\n",
    "        print(fname)\n",
    "        continue \n",
    "    labels.append(int(fname[6]))\n",
    "    dataset.append(get_range_doppler(f'train/{fname}'))\n",
    "\n",
    "dataset = np.array(dataset) \n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b44ee442",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_unfit = dataset \n",
    "dataset = np.array([x[:179, :] for x in dataset_unfit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a018f729",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130, 179, 256)\n",
      "(130,)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "79a399d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_hot = np.zeros((labels.size, labels.max()))\n",
    "labels_hot[np.arange(labels.size),labels-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "504f2feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import isfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10af508",
   "metadata": {},
   "source": [
    "# Layer Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10043488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrcn.base.blocks import InputToNode, BatchIntrinsicPlasticity, NodeToNode, HebbianNodeToNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e9a79e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrcn.echo_state_network import ESNRegressor, ESNClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7258097",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_rd = get_range_doppler(DEFAULT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5a730f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1_size = 500\n",
    "layer2_size = 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a6171882",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_params = {'hidden_layer_size': layer2_size, #1000 in 5C\n",
    "                  'input_activation': 'identity', #\n",
    "                  # 'k_in': layer1_size, # number of inputs \n",
    "                  'bias_scaling': 0.0, # usually 0 \n",
    "                  'spectral_radius' : 0.0, \n",
    "                  'reservoir_activation': 'tanh', # 2\n",
    "                  'leakage': 0.05, #equation 6, 17 frames should be 1 step \n",
    "                  'bidirectional': True, #bidirectional \n",
    "                  'k_rec': 10,\n",
    "                  'alpha': 1e-5,\n",
    "                  'random_state': 1,\n",
    "                  'requires_sequence': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "67c80351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bilayered; i2n -> n2o, second layer has fewer (125) nodes\n",
    "\n",
    "i2n = InputToNode(hidden_layer_size=layer1_size, input_activation=\"tanh\", input_scaling=1.0, bias_scaling=0.1)\n",
    "\n",
    "# layer1 = i2n.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "60a03477",
   "metadata": {},
   "outputs": [],
   "source": [
    "n2o = ESNClassifier(input_to_node = i2n, **initial_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "69d1ed70",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (895,) into shape (5,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [195]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mn2o\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_hot\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.8/site-packages/pyrcn/echo_state_network/_esn.py:743\u001b[0m, in \u001b[0;36mESNClassifier.fit\u001b[0;34m(self, X, y, n_jobs, transformer_weights)\u001b[0m\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_node_to_node\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_to_node\u001b[38;5;241m.\u001b[39mtransform(X[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_if_sequence_to_value(X, y)\n\u001b[0;32m--> 743\u001b[0m     X, y, sequence_ranges \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_sequences\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence_to_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sequence_to_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    746\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, y, multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.8/site-packages/pyrcn/util/_util.py:109\u001b[0m, in \u001b[0;36mconcatenate_sequences\u001b[0;34m(X, y, sequence_to_value)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sequence_to_value:\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(y):\n\u001b[0;32m--> 109\u001b[0m         y[k] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrepeat(y[k], X[k]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    111\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m    112\u001b[0m sequence_ranges: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray([])\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (895,) into shape (5,)"
     ]
    }
   ],
   "source": [
    "n2o.fit(dataset, labels_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "05447f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESNRegressor(input_to_node=InputToNode(bias_scaling=0.0, hidden_layer_size=125,\n",
      "                                       input_activation='identity', k_in=256,\n",
      "                                       random_state=1),\n",
      "             node_to_node=NodeToNode(bidirectional=True, hidden_layer_size=125,\n",
      "                                     k_rec=10, leakage=0.05, random_state=1,\n",
      "                                     spectral_radius=0.0),\n",
      "             regressor=IncrementalRegression(), requires_sequence=True)\n"
     ]
    }
   ],
   "source": [
    "print(n2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "10617fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256,)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[row,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9504b760",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ESNRegressor' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [93]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m [] \n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(dataset\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]): \n\u001b[0;32m----> 3\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(\u001b[43mn2o\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m(dataset[row:row\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,:]))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ESNRegressor' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "predictions = [] \n",
    "for row in range(dataset.shape[0]): \n",
    "    predictions.append(n2o.predict_proba(dataset[row:row+1,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "4d37a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrcn.datasets import mackey_glass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "d3aa3ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mackey_glass(n_timesteps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ee2c71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "echo-venv",
   "language": "python",
   "name": "echo-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
