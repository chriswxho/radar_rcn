{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a161a5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f307dd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0451637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['System Volume Information',\n",
       " '$RECYCLE.BIN',\n",
       " '.Spotlight-V100',\n",
       " 'Xilinx',\n",
       " '.fseventsd',\n",
       " 'ECG_data',\n",
       " 'Research Code',\n",
       " 'IDRad',\n",
       " 'REDS',\n",
       " 'Vimeo']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.listdir('/Volumes/Untitled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fb00dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR = '/Volumes/Untitled/IDRad/idrad'\n",
    "DATA_DIR = 'idrad'\n",
    "DEFAULT_FILE = 'train/target5_001.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e011a7c0",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aefcc3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_doppler(data, chirps=256,\n",
    "                  samples=256,\n",
    "                  fft_rangesamples=2 ** 10,\n",
    "                  fft_dopplersamples=2 ** 8,\n",
    "                  fs=2.0e6,\n",
    "                  kf=1171875.0e7,\n",
    "                  min_range=0.5,\n",
    "                  max_range=10):\n",
    "    \"\"\"\n",
    "    Computes a range-doppler map for a given number of chirps and samples per chirp.\n",
    "    :param data: FMCW radar data frame consisting of <chirps>x<samples>\n",
    "    :param chirps: Number of chirps (Np)\n",
    "    :param samples: Number of samples (N)\n",
    "    :param fft_rangesamples: Number of samples for the range fft.\n",
    "    :param fft_dopplersamples: Number of samples for the doppler fft.\n",
    "    :param fs: Constant depending on the radar recording parameters.\n",
    "    :param kf: Constant depending on the radar recording parameters.\n",
    "    :param min_range: Minimum value to take into account for the range axis in the range-doppler map.\n",
    "    :param max_range: Maximum value to take into account for the range axis in the range-doppler map.\n",
    "    :return: Returns a 2D dimensional range-doppler map representing the reflected power over all range-doppler bins.\n",
    "    \"\"\"\n",
    "\n",
    "    data = data.reshape(chirps, samples).T\n",
    "    # Ignore chirp sequence number\n",
    "    data = data[1:]\n",
    "    Ny, Nx = data.shape  # rows (N), columns (Np)\n",
    "\n",
    "    window = np.hanning(Ny)\n",
    "    scaled = np.sum(window)\n",
    "    window2d = np.tile(window, (Nx, 1)).T\n",
    "    data = data * window2d\n",
    "\n",
    "    # Calculate Range FFT\n",
    "    x = np.zeros((fft_rangesamples, Nx))\n",
    "    start_index = int((fft_rangesamples - Ny) / 2)\n",
    "    x[start_index:start_index + Ny, :] = data\n",
    "    X = np.fft.fft(x, fft_rangesamples, 0) / scaled * (2.0 / 2048)\n",
    "    # Extract positive range bins\n",
    "    X = X[0:fft_rangesamples // 2, :]\n",
    "    # Extract range\n",
    "    _freq = np.arange(fft_rangesamples // 2) / float(fft_rangesamples) * fs\n",
    "    _range = _freq * 3e8 / (2 * kf)\n",
    "    min_index = np.argmin(np.abs(_range - min_range))\n",
    "    max_index = np.argmin(np.abs(_range - max_range))\n",
    "\n",
    "    X = X[min_index: max_index, :]\n",
    "\n",
    "    # Calculate Doppler FFT\n",
    "    Ny, Nx = X.shape\n",
    "    window = np.hanning(Nx)\n",
    "    scaled = np.sum(window)\n",
    "    window2d = np.tile(window, (Ny, 1))\n",
    "    X = X * window2d\n",
    "\n",
    "    rd = np.zeros((Ny, fft_dopplersamples), dtype='complex_')\n",
    "    start_index = int((fft_dopplersamples - Nx) / 2)\n",
    "    rd[:, start_index:start_index + Nx] = X\n",
    "\n",
    "    range_doppler = np.fft.fft(rd, fft_dopplersamples, 1) / scaled\n",
    "    range_doppler = np.fft.fftshift(range_doppler, axes=1)\n",
    "\n",
    "    return np.abs(range_doppler)\n",
    "\n",
    "def preprocess_file(fname): \n",
    "    with h5py.File(f'{DATA_DIR}/{fname}', 'r+') as file:\n",
    "        nframes = file['radar'].shape[0]\n",
    "\n",
    "        # Create datasets\n",
    "        if not 'microdoppler' in file:\n",
    "            file.create_dataset(\"microdoppler\", (nframes, 256), dtype='float32', chunks=(1, 256))\n",
    "        if not 'microdoppler_thresholded' in file:\n",
    "            file.create_dataset(\"microdoppler_thresholded\", (nframes, 256), dtype='float32', chunks=(1, 256))\n",
    "        if not 'range_doppler' in file:\n",
    "            file.create_dataset(\"range_doppler\", (nframes, 380, 256), dtype='float32', chunks=True)\n",
    "\n",
    "        \n",
    "        x = file['range_doppler'][:10,:,:]\n",
    "        \n",
    "        #has not been preprocessed\n",
    "        if np.all(x==0): \n",
    "            print('preprocessing')\n",
    "        \n",
    "            # Run over each radar frame\n",
    "            for i in range(nframes): # only take first 1000 \n",
    "                rd = range_doppler(file['radar'][i]) \n",
    "                rd = 20 * np.log10(rd)\n",
    "\n",
    "                file['range_doppler'][i] = rd\n",
    "                file['microdoppler'][i] = rd.sum(axis=0)\n",
    "\n",
    "                rd -= np.amax(rd)\n",
    "                rd[rd < -45] = -45\n",
    "                file['microdoppler_thresholded'][i] = rd.sum(axis=0)\n",
    "\n",
    "                if not i%100: \n",
    "                    print(\"Finished frame %d of %d.\" % (i + 1, nframes))\n",
    "                    \n",
    "def get_range_doppler(fname): \n",
    "    '''returns the range doppler'''\n",
    "    preprocess_file(fname) \n",
    "    range_doppler = 0 \n",
    "    \n",
    "    with h5py.File(f'{DATA_DIR}/{fname}', 'r+') as file:\n",
    "        # d['microdoppler'] = file['microdoppler'][:,:]\n",
    "        # d['microdoppler_thresholded'] = file['microdoppler_thresholded'][:,:]\n",
    "        range_doppler = file['range_doppler'][:,:,:].sum(axis=(0,1))\n",
    "    \n",
    "    return range_doppler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ef8c7fc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "._target2_017.hdf5\n",
      "._target3_105.hdf5\n",
      "._target3_113.hdf5\n",
      "._target1_073.hdf5\n",
      "._target4_051.hdf5\n",
      "._target3_129.hdf5\n",
      "._target4_047.hdf5\n",
      "._target4_067.hdf5\n",
      "._target3_109.hdf5\n",
      "._target1_090.hdf5\n",
      "._target2_021.hdf5\n",
      "._target1_086.hdf5\n",
      "._target3_125.hdf5\n",
      "._target1_069.hdf5\n",
      "._target1_087.hdf5\n",
      "._target3_124.hdf5\n",
      "._target1_068.hdf5\n",
      "._target2_020.hdf5\n",
      "._target1_091.hdf5\n",
      "._target3_108.hdf5\n",
      "._target4_066.hdf5\n",
      "._target4_046.hdf5\n",
      "._target3_128.hdf5\n",
      "._target4_050.hdf5\n",
      "._target1_072.hdf5\n",
      "._target3_112.hdf5\n",
      "._target3_104.hdf5\n",
      "._target2_016.hdf5\n",
      "._target4_036.hdf5\n",
      "._target4_061.hdf5\n",
      "._target3_119.hdf5\n",
      "._target1_096.hdf5\n",
      "._target1_079.hdf5\n",
      "._target2_027.hdf5\n",
      "._target2_031.hdf5\n",
      "._target1_080.hdf5\n",
      "._target3_123.hdf5\n",
      "._target2_011.hdf5\n",
      "._target3_103.hdf5\n",
      "._target3_115.hdf5\n",
      "._target2_007.hdf5\n",
      "._target1_075.hdf5\n",
      "._target4_057.hdf5\n",
      "._target4_041.hdf5\n",
      "._target4_040.hdf5\n",
      "._target5_001.hdf5\n",
      "._target4_056.hdf5\n",
      "._target1_074.hdf5\n",
      "._target2_006.hdf5\n",
      "._target3_114.hdf5\n",
      "._target3_102.hdf5\n",
      "._target2_010.hdf5\n",
      "._target1_081.hdf5\n",
      "._target3_122.hdf5\n",
      "._target2_030.hdf5\n",
      "._target2_026.hdf5\n",
      "._target1_097.hdf5\n",
      "._target1_078.hdf5\n",
      "._target3_118.hdf5\n",
      "._target4_060.hdf5\n",
      "._target4_037.hdf5\n",
      "._target3_121.hdf5\n",
      "._target1_082.hdf5\n",
      "._target2_033.hdf5\n",
      "._target2_025.hdf5\n",
      "._target1_094.hdf5\n",
      "._target4_059.hdf5\n",
      "._target2_009.hdf5\n",
      "._target4_063.hdf5\n",
      "._target4_043.hdf5\n",
      "._target5_002.hdf5\n",
      "._target2_029.hdf5\n",
      "._target4_055.hdf5\n",
      "._target1_077.hdf5\n",
      "._target1_098.hdf5\n",
      "._target2_005.hdf5\n",
      "._target3_117.hdf5\n",
      "._target3_101.hdf5\n",
      "._target4_038.hdf5\n",
      "._target2_013.hdf5\n",
      "._target2_012.hdf5\n",
      "._target4_039.hdf5\n",
      "._target3_100.hdf5\n",
      "._target3_116.hdf5\n",
      "._target2_004.hdf5\n",
      "._target1_076.hdf5\n",
      "._target1_099.hdf5\n",
      "._target4_054.hdf5\n",
      "._target2_028.hdf5\n",
      "._target5_003.hdf5\n",
      "._target4_042.hdf5\n",
      "._target4_062.hdf5\n",
      "._target2_008.hdf5\n",
      "._target4_058.hdf5\n",
      "._target1_095.hdf5\n",
      "._target2_024.hdf5\n",
      "._target2_032.hdf5\n",
      "._target3_120.hdf5\n",
      "._target1_083.hdf5\n",
      "._target4_045.hdf5\n",
      "._target1_088.hdf5\n",
      "._target4_053.hdf5\n",
      "._target1_071.hdf5\n",
      "._target3_111.hdf5\n",
      "._target3_107.hdf5\n",
      "._target2_015.hdf5\n",
      "._target3_127.hdf5\n",
      "._target1_084.hdf5\n",
      "._target4_049.hdf5\n",
      "._target2_035.hdf5\n",
      "._target2_023.hdf5\n",
      "._target1_092.hdf5\n",
      "._target4_065.hdf5\n",
      "._target2_019.hdf5\n",
      "._target2_018.hdf5\n",
      "._target4_064.hdf5\n",
      "._target3_130.hdf5\n",
      "._target1_093.hdf5\n",
      "._target2_022.hdf5\n",
      "._target2_034.hdf5\n",
      "._target4_048.hdf5\n",
      "._target3_126.hdf5\n",
      "._target1_085.hdf5\n",
      "._target2_014.hdf5\n",
      "._target3_106.hdf5\n",
      "._target3_110.hdf5\n",
      "._target1_070.hdf5\n",
      "._target4_052.hdf5\n",
      "._target1_089.hdf5\n",
      "._target4_044.hdf5\n"
     ]
    }
   ],
   "source": [
    "dataset_files = os.listdir(f'{DATA_DIR}/train')\n",
    "dataset = [] \n",
    "labels = []\n",
    "\n",
    "for fname in dataset_files: \n",
    "    if fname[:2] == '._':\n",
    "        print(fname)\n",
    "        continue \n",
    "    labels.append(int(fname[6]))\n",
    "    dataset.append(get_range_doppler(f'train/{fname}'))\n",
    "\n",
    "dataset = np.array(dataset) \n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b44ee442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130, 256)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "504f2feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import isfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10af508",
   "metadata": {},
   "source": [
    "# Layer Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10043488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrcn.base.blocks import InputToNode, BatchIntrinsicPlasticity, NodeToNode, HebbianNodeToNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6171882",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_params = {'hidden_layer_size': 125, #1000 in 5C\n",
    "                  'input_activation': 'identity', #\n",
    "                  'k_in': 256, # number of inputs \n",
    "                  'bias_scaling': 0.0, # usually 0 \n",
    "                  'spectral_radius' : 0.0, \n",
    "                  'reservoir_activation': 'tanh', # 2\n",
    "                  'leakage': 0.05, #equation 6, 17 frames should be 1 step \n",
    "                  'bidirectional': True, #bidirectional \n",
    "                  'k_rec': 10,\n",
    "                  'alpha': 1e-5,\n",
    "                  'random_state': 1,\n",
    "                  'requires_sequence': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7258097",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_rd = get_range_doppler(DEFAULT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67c80351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bilayered; i2n -> n2o, second layer has fewer (125) nodes\n",
    "\n",
    "i2n = InputToNode(hidden_layer_size=500, input_activation=\"tanh\", input_scaling=1.0, bias_scaling=0.1)\n",
    "\n",
    "layer1 = i2n.fit_transform(default_rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9a79e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrcn.echo_state_network import ESNRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60a03477",
   "metadata": {},
   "outputs": [],
   "source": [
    "n2o = ESNRegressor(input_to_node = i2n, **initial_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69d1ed70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ESNRegressor(input_to_node=InputToNode(bias_scaling=0.0,\n",
       "                                       input_activation='identity', k_in=256,\n",
       "                                       random_state=1),\n",
       "             node_to_node=NodeToNode(bidirectional=True, k_rec=10, leakage=0.05,\n",
       "                                     random_state=1, spectral_radius=0.0),\n",
       "             regressor=IncrementalRegression(), requires_sequence=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n2o.fit(dataset, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "echo-venv",
   "language": "python",
   "name": "echo-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
